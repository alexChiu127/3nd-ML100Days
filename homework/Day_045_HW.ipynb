{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=tH9FH1DH5n0 李弘毅教授影片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting 是利用gradient來進行boosting(修正上一棵樹的錯誤而形成一顆修正過後的樹，有順序性，一個做完才能做下一個)，再把每一顆樹以weighting方式集合起來,得到最終模型。\n",
    "此方法適用於較弱的模型,解決Random forest(Decision Tree做baggin的版本,避免overfitting)法以bagging方式(resampling，無順序性，可以一起做)無法處理弱模型較難fit data的缺點。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
